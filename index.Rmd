<br> 
<center><img src="https://i.imgur.com/AbCCpQO.png" width="700"></center>


_____

<a id='TOC'></a>

# Tabular data: Univariate Numerical


_____

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'))
```

Let's load the data we previously used on schools:

```{r getData, eval=TRUE}
rm(list = ls()) # clean memory

location='https://github.com/DACSS-Visual/tabular_univar_cat/raw/main/data/'
file='eduwa.rda'
link=paste0(location,file)


#getting the data TABLE from the file in the cloud:
load(file=url(link))
```

Let me use the variable _Reduced.Lunch_ which informs how many kids there are in each school that offer  lunch for a reduced price. We have more than 2000 schools, so it is unlikely we find few different values. This is how many different values we have:

```{r unique, eval=TRUE}
# how many unique values
length(unique(eduwa$Reduced.Lunch))
```

These are too many different values. Then, the bar plot is not a good idea (and neither a frequency table), as the bar plot produces a bar for _each_ unique value in the data. This is how a bar plot will look for this variable:

```{r, eval=TRUE}
# from table to dataframe
lunchDF=as.data.frame(table(eduwa$Reduced.Lunch))
names(lunchDF)=c("Reduced_Lunch_Beneficiaries","Count")

# plotting from data frame
library(ggplot2)
base1=ggplot(data=lunchDF, aes(x=Reduced_Lunch_Beneficiaries,Count))
bar1_bad=base1+geom_bar(stat = "identity")
bar1_bad
```

The variety of numerical data requires statistical exploration with some questions in mind:

* What is the representative value? Generally the **mean**, or **median**. 

* How good is the representative value? You need some measure of dispersion. For the mean you have the **standard deviation** and **coefficient of variation**, and for the median the **median absolute deviation**. 

* Does the shape of the distribution differs from a _normal_ distribution? If there is **asymmetry**, is it large enough to show **outliers**? You need some  measure of symmetry and shape (a.k.a. _kurtosis_).


First, let's take a look at the basic statistical information:

```{r summary, eval=TRUE}
summary(eduwa$Reduced.Lunch)
```
This information may give us a general idea on how the data on _reduced lunch_ is behaving, so we select the plot that highlights that behavior. Let me try a box plot:

```{r boxPlotbasic}
base= ggplot(eduwa,aes(y = Reduced.Lunch))  #var to plot in 'y' 
base + geom_boxplot()
```

That is our starting point. Now, let's follow some steps to change the previous boxplot:

1. What should the y-axis show? 

```{r, eval=TRUE}
# get all the summary values but the count of NAs.
(statVals=summary(eduwa$Reduced.Lunch,digits = 3)[1:6])
```
Instead of the default values, we could put those values in the boxplot y-axis:

```{r, eval=TRUE, warning=FALSE, message=FALSE}
library(magrittr)
# the summary values as vector
statVals=statVals%>%as.vector() #notice '%>%'

#plotting
base= ggplot(eduwa,aes(y = Reduced.Lunch))  
b1= base + geom_boxplot() 
b1=b1+ scale_y_continuous(breaks = statVals) #custom breaks
b1
```
In general, flipping can help:

```{r}
b1=b1 +coord_flip()
b1

```

3. Should we annotate?

What about:
* The upper limit (before outliers appear).
* The amount of outliers limit (before outliers appear).

We get the upper limit like this:

```{r, warning=FALSE}
(upperT=ggplot_build(b1)$data[[1]]$ymax)
```

We can compute the _amount of outliers_ on the right tail like this:

```{r, eval=TRUE}
(numOutliers=sum(eduwa$Reduced.Lunch>upperT,na.rm = T))
```

Let's annotate

```{r, eval=TRUE,warning=FALSE, message=FALSE}

# text for annotations
txtOutliers=paste0('#Outlying schools: ',numOutliers)
txtUpper=paste0('Threshold:',upperT)


b1_vertical = b1 + geom_hline(yintercept = upperT,
                            color='red',
                            linetype="dotted",
                            size=2) 
b1_annot=b1_vertical + annotate(geom = 'text',
                                label=txtUpper,
                                y = upperT+5,
                                x=0.2,
                                angle=90) # text angle

b1_annot=b1_annot + annotate(geom = 'text',
                                label=txtOutliers,
                                y = upperT+60,
                                x=0.1,
                                angle=0)
b1_annot
```

3. Do we need the values in the vertical axis?

```{r, eval=TRUE,warning=FALSE, message=FALSE}
b1_annot_noX = b1_annot + 
                theme(axis.text.y = element_blank(),
                      axis.ticks.y = element_blank(),
                      axis.title.y = element_blank())
b1_annot_noX
```

4. What may need further changes?

* What about choosing a different theme (grid)?

```{r}
b1_newGrid=b1_annot_noX +  theme(panel.grid = element_blank())
b1_newGrid
```

* Maybe the text in the horizontal is not easy to read yet?

```{r}
b1_newGrid_axisText = b1_newGrid+ theme(axis.text.x = element_text(angle = 60,
                                                                  size = 7,
                                                                  vjust = 0.5))
b1_newGrid_axisText
```


In general, numerical data are prone to have outliers in real life (it is not common to speak about outliers in ordinal data since they have few levels).



The **summary** command can be supplemented with some measures of spread or dispersion:

```{r, eval=TRUE}
# standard deviation:
sd(eduwa$Reduced.Lunch,na.rm = T)
```

```{r, eval=TRUE}
# median absolute deviation:
mad(eduwa$Reduced.Lunch,na.rm = T)
```

```{r, warning=FALSE}
# coefficient of variation
library(DescTools)
CoefVar(eduwa$Reduced.Lunch,
        na.rm = T)
```

There are also measures of shape:

```{r, eval=TRUE, message=FALSE}
# asymmetry
Skew(eduwa$Reduced.Lunch,
     na.rm = T)

```

```{r, eval=TRUE}
# kurtosis
Kurt(eduwa$Reduced.Lunch,
     na.rm = T)
```

And the confidence interval for the mean:

```{r, eval=TRUE, message=FALSE}
# confidence interval for the mean
MeanCI(eduwa$Reduced.Lunch,
     na.rm = T)
```

*What do we know right now?*

1. The data is skewed, with a right tail.
2. The data is concentrated in a small group of values.
3. In this situation, the median is more informative than the mean.


You can save those values for future annotations:

```{r}
cv=CoefVar(eduwa$Reduced.Lunch,na.rm = T)
sd=SD(eduwa$Reduced.Lunch,na.rm = T)
md=Median(eduwa$Reduced.Lunch,na.rm = T)
mn=Mean(eduwa$Reduced.Lunch,na.rm = T)
mn.low=MeanCI(eduwa$Reduced.Lunch,
     na.rm = T)[['lwr.ci']]
mn.up=MeanCI(eduwa$Reduced.Lunch,
     na.rm = T)[['upr.ci']]
sk=Skew(eduwa$Reduced.Lunch,
     na.rm = T)
```


A key visual for numerical data is the **histogram**. The histogram looks like a bar plot. In both cases the height of the bars represent counts/percents, but the bars in the histogram are consecutive while the bases of the bars are numeric intervals (**binwidth** informs the width of the intervals). Histograms mainly help you see clearly where and how many _peaks_ there are in the data distribution. Let's make one:

```{r GGLikeBase,eval=TRUE,warning=FALSE, message=FALSE}
#ggplot
barWIDTH=10
library(ggplot2)
base= ggplot(eduwa)  
h1= base + geom_histogram(aes(x = Reduced.Lunch),
                          binwidth = barWIDTH,
                          fill='black') 
h1=h1 + labs(y="count")
h1
```

Let's do some annotations:

```{r, eval=TRUE,warning=FALSE, message=FALSE}
# texts
txtMean=paste0('Mean:',round(mn))
txtSkew=paste0('Skeness:',round(sk,2))

# adding
h1_ann=h1+ geom_vline(xintercept = mn,color='red') + # mean as line
    # about the mean
    annotate(geom = 'text',color='red',
             label=txtMean, # mean as text
              y = 400,
              x=mn+5,
              angle=90) + 
    # about the skewness
    annotate(geom = 'text', color='blue',
             label=txtSkew, # skewness as text
              y = 50,
              x=upperT+170,
              angle=0) 

h1_ann    
```


We know this variable has one peak, it is highly skewed, and it has outliers at the top and the bottom values. We could try to combine all that in one visual:

```{r,warning=FALSE, message=FALSE}
library(ggpubr)
ggarrange(h1_ann,b1_newGrid_axisText,align='v',ncol = 1,heights = 2:4)

```

As you see, that is not an exact match. An alternative can be the **violin** plot.


```{r, warning=FALSE}
base=ggplot(eduwa, aes(x=0,y=Reduced.Lunch))+
            theme_classic()

vio=base+geom_violin(trim=FALSE, fill="grey")

viobox=vio+geom_boxplot(width=0.1,outlier.color = 'red',colour = 'white',fill='black')
viobox=viobox + coord_flip() + 
                theme(axis.text.y = element_blank(),
                      axis.ticks.y = element_blank(),
                      axis.title.y = element_blank()) + annotate(geom = 'text',
                                label=txtOutliers,
                                y = upperT+60,
                                x=0.1,color='red',
                                angle=0)
viobox 
```

The violin plot will inform the presence of peaks, but not on the maximum value of the peak as the histogram shows.

_____

[Go to top of document.](#part0)

_____

<a id='part3'></a>


# First Deliverable (Option 2)

* Alternative 1: Prepare a plot for the column **Student.Teacher.Ratio**.

* Alternative 2: Aggregate _Reduced.Lunch_ by summing up per County, so that you can prepare a Pareto visual:

```{r}
reducedLunch_county=aggregate(data=eduwa,
                              Reduced.Lunch~County,
                              FUN=sum)
reducedLunch_county
```


```{r}
library(ggQC) # install this previously

base=ggplot(data=reducedLunch_county,
             aes(x=County,y=Reduced.Lunch)) + # just the counts
     theme_classic()
paretoDraft=base + stat_pareto() 
paretoDraft

```

You job is to create this plot step by step without using the **ggQC** library.


_____

[Go to top of document.](#part0)
